dataset_name: "nonlinear_gssm"
dataset_params:
  n_time_steps: 25
  n_train_samples: 5000
  n_val_samples: 512
  n_test_samples: 512
  batch_size: 512
  return_latents: False
  return_times: False

model_name: "DMMContinuous"
model_params:
  st_net_hidden_dim: 256
  st_net_n_layers: 2
  latent_dim: 2
  obs_dim: 2

loss_name: "DMMContinuousELBO"
loss_params:
  rmse_eval_latent: False
  z0_log_var: 0
  annealing_params:
    enabled: False
    warm_up: 25 # How many epochs before start adding KL term
    n_epochs_for_full: 100 # How many epochs to reach full KL term (will have weight 1 at this value + warmup)

trainer_name: "DeepTrainer"
trainer_params:
  n_epochs: 350
  lr: 0.0005
  val_freq: 10 # Validate every 10 epochs
  save_path: "models/dmm/nonlinear_synthetic.pth"
  device: "cuda"
  verbose: False
  eval_window_shifts: [0, 1, 2, 3, 4, 5]
  n_eval_windows: 5 # How many times to shift the window (starting from the end) for evaluation
  
logger_name: "WandbLogger"
logger_params: {}

