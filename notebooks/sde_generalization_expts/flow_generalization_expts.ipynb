{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from flow_model import Flow\n",
    "from utils import gaussian_nll, gen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dist_std = 10\n",
    "source_fn = lambda x: 0.004*x*x\n",
    "target_fn = lambda x: 0\n",
    "device = \"cpu\"\n",
    "exp_name = \"quad_line\"\n",
    "use_x_dist = False\n",
    "\n",
    "x_dist_std = 10\n",
    "source_fn = lambda x: torch.cos(x)\n",
    "target_fn = lambda x: torch.sin(x)\n",
    "device = \"cpu\"\n",
    "exp_name = \"cos_sin\"\n",
    "use_x_dist = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_neg_log_prob(points):\n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    gt = target_fn(x)\n",
    "\n",
    "    loss_d0 = gaussian_nll(0, np.log(x_dist_std**2), x)\n",
    "    loss_d1 = gaussian_nll(gt, np.log(0.05), y)\n",
    "\n",
    "    total_loss = loss_d1\n",
    "    if use_x_dist:\n",
    "        total_loss += loss_d0\n",
    "        \n",
    "    return total_loss\n",
    "loaders = gen_data(x_dist_std,\n",
    "                   source_fn,\n",
    "                   target_fn,\n",
    "                   source_std=0.05,\n",
    "                   target_std=0.05,\n",
    "                   num_points=1024,\n",
    "                   batch_size=512)\n",
    "\n",
    "points2 = next(iter(loaders['source'])).numpy()\n",
    "plt.scatter(points2[:,0], points2[:,1], label=\"Source Dist\")\n",
    "\n",
    "points = next(iter(loaders['target'])).numpy()\n",
    "plt.scatter(points[:,0], points[:,1], label=\"Target Dist\")\n",
    "plt.xlim(-30,30)\n",
    "plt.ylim(-5,5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Flow(128, 32).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for e in  tqdm(range(2000)):\n",
    "    losses = []\n",
    "    for data in loaders[\"source\"]:\n",
    "        data = data.float().to(device)\n",
    "\n",
    "        target_samples, log_jacobian = model(data)\n",
    "\n",
    "        mean = torch.zeros_like(target_samples)\n",
    "        log_var = torch.zeros_like(target_samples)\n",
    "\n",
    "        log_p = target_neg_log_prob(target_samples)\n",
    "\n",
    "        neg_log_likelihood = log_p - log_jacobian\n",
    "        neg_log_likelihood = neg_log_likelihood.mean()/2 # nats per dim\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        neg_log_likelihood.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(neg_log_likelihood.item())\n",
    "print(\"Final negative log likelihood: {:.2f}\".format(np.mean(losses)))\n",
    "\n",
    "os.makedirs('plots_flow', exist_ok=True)\n",
    "os.makedirs(f'plots_flow/{exp_name}', exist_ok=True)\n",
    "\n",
    "data = loaders[\"source\"].dataset.float().to(device)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.scatter(data[:,0].detach().cpu().numpy(), data[:,1].detach().cpu().numpy(), color=\"blue\")\n",
    "    plt.grid()\n",
    "    plt.xlim(-10,10)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "\n",
    "    plt.savefig(f'plots_flow/{exp_name}/frame_{i:03d}.png')\n",
    "    plt.close()  # Close the plot to avoid display\n",
    "\n",
    "    data = model.forward(data)[0]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
